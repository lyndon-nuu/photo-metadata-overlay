import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { renderHook, act } from '@testing-library/react';\nimport { useBatchProcessor } from '../../hooks/useBatchProcessor';\nimport {\n  mockPhotoMetadata,\n  mockOverlaySettings,\n  mockFrameSettings,\n  createTestFilesBatch,\n  PerformanceMonitor,\n  getMemoryUsage,\n  waitFor,\n  restoreMocks,\n} from '../../test/test-utils';\n\n// Mock the image processing service\nvi.mock('../../services/image-processing.service', () => ({\n  imageProcessingService: {\n    loadImage: vi.fn().mockResolvedValue({\n      naturalWidth: 1920,\n      naturalHeight: 1080,\n    }),\n    applyOverlay: vi.fn().mockResolvedValue({\n      width: 1920,\n      height: 1080,\n      getContext: () => ({}),\n    }),\n    applyFrame: vi.fn().mockResolvedValue({\n      width: 1940,\n      height: 1100,\n      getContext: () => ({}),\n    }),\n    exportImage: vi.fn().mockResolvedValue(\n      new Blob(['mock-image-data'], { type: 'image/jpeg' })\n    ),\n  },\n}));\n\n// Mock fetch for file loading\nglobal.fetch = vi.fn().mockResolvedValue({\n  blob: () => Promise.resolve(new Blob(['mock-file-data'], { type: 'image/jpeg' })),\n});\n\ndescribe('Batch Processing E2E Tests', () => {\n  let performanceMonitor: PerformanceMonitor;\n\n  beforeEach(() => {\n    performanceMonitor = new PerformanceMonitor();\n    vi.clearAllMocks();\n  });\n\n  afterEach(() => {\n    restoreMocks();\n  });\n\n  describe('Basic Batch Processing', () => {\n    it('should process a small batch of files successfully', async () => {\n      const files = createTestFilesBatch(3);\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 1,\n      }));\n\n      expect(result.current.isProcessing).toBe(false);\n      expect(result.current.progress.status).toBe('idle');\n\n      performanceMonitor.start();\n      \n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      const duration = performanceMonitor.end('small-batch');\n\n      expect(result.current.isProcessing).toBe(false);\n      expect(result.current.progress.status).toBe('completed');\n      expect(result.current.results).toBeDefined();\n      expect(result.current.results!.total).toBe(3);\n      expect(result.current.results!.successful).toBe(3);\n      expect(result.current.results!.failed).toBe(0);\n      expect(duration).toBeLessThan(5000); // Should complete in less than 5 seconds\n    });\n\n    it('should process a medium batch with concurrency', async () => {\n      const files = createTestFilesBatch(10);\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 3, // Process 3 files concurrently\n      }));\n\n      performanceMonitor.start();\n      \n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      const duration = performanceMonitor.end('medium-batch-concurrent');\n\n      expect(result.current.results).toBeDefined();\n      expect(result.current.results!.total).toBe(10);\n      expect(result.current.results!.successful).toBe(10);\n      expect(duration).toBeLessThan(10000); // Should be faster with concurrency\n    });\n\n    it('should process a large batch efficiently', async () => {\n      const files = createTestFilesBatch(50);\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 5,\n      }));\n\n      performanceMonitor.start();\n      \n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      const duration = performanceMonitor.end('large-batch');\n\n      expect(result.current.results).toBeDefined();\n      expect(result.current.results!.total).toBe(50);\n      expect(result.current.results!.successful).toBe(50);\n      expect(duration).toBeLessThan(30000); // Should complete in less than 30 seconds\n    });\n  });\n\n  describe('Progress Tracking', () => {\n    it('should track progress accurately', async () => {\n      const files = createTestFilesBatch(5);\n      const progressUpdates: number[] = [];\n      \n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 1,\n        onProgress: (progress) => {\n          progressUpdates.push(progress.percentage);\n        },\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      expect(progressUpdates.length).toBeGreaterThan(0);\n      expect(progressUpdates[progressUpdates.length - 1]).toBe(100);\n      \n      // Progress should be monotonically increasing\n      for (let i = 1; i < progressUpdates.length; i++) {\n        expect(progressUpdates[i]).toBeGreaterThanOrEqual(progressUpdates[i - 1]);\n      }\n    });\n\n    it('should provide accurate time estimates', async () => {\n      const files = createTestFilesBatch(10);\n      let hasTimeEstimate = false;\n      \n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 1,\n        onProgress: (progress) => {\n          if (progress.estimatedTimeRemaining !== undefined) {\n            hasTimeEstimate = true;\n            expect(progress.estimatedTimeRemaining).toBeGreaterThan(0);\n          }\n        },\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      expect(hasTimeEstimate).toBe(true);\n    });\n  });\n\n  describe('Error Handling', () => {\n    it('should handle individual file processing errors', async () => {\n      const files = createTestFilesBatch(5);\n      const errors: any[] = [];\n      \n      // Mock one file to fail\n      const { imageProcessingService } = await import('../../services/image-processing.service');\n      (imageProcessingService.loadImage as any)\n        .mockResolvedValueOnce({ naturalWidth: 1920, naturalHeight: 1080 })\n        .mockRejectedValueOnce(new Error('File processing failed'))\n        .mockResolvedValue({ naturalWidth: 1920, naturalHeight: 1080 });\n\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 1,\n        onError: (error) => {\n          errors.push(error);\n        },\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      expect(result.current.results).toBeDefined();\n      expect(result.current.results!.total).toBe(5);\n      expect(result.current.results!.successful).toBe(4);\n      expect(result.current.results!.failed).toBe(1);\n      expect(errors.length).toBe(1);\n      expect(errors[0].error).toBe('File processing failed');\n    });\n\n    it('should retry failed files when configured', async () => {\n      const files = createTestFilesBatch(3);\n      let attemptCount = 0;\n      \n      const { imageProcessingService } = await import('../../services/image-processing.service');\n      (imageProcessingService.loadImage as any).mockImplementation(() => {\n        attemptCount++;\n        if (attemptCount <= 2) {\n          return Promise.reject(new Error('Temporary failure'));\n        }\n        return Promise.resolve({ naturalWidth: 1920, naturalHeight: 1080 });\n      });\n\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 1,\n        retryAttempts: 2,\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files.slice(0, 1), // Process only one file\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      expect(result.current.results).toBeDefined();\n      expect(result.current.results!.successful).toBe(1);\n      expect(attemptCount).toBe(3); // Initial attempt + 2 retries\n    });\n  });\n\n  describe('Concurrency Control', () => {\n    it('should respect concurrency limits', async () => {\n      const files = createTestFilesBatch(10);\n      let maxConcurrentCalls = 0;\n      let currentConcurrentCalls = 0;\n      \n      const { imageProcessingService } = await import('../../services/image-processing.service');\n      (imageProcessingService.loadImage as any).mockImplementation(async () => {\n        currentConcurrentCalls++;\n        maxConcurrentCalls = Math.max(maxConcurrentCalls, currentConcurrentCalls);\n        \n        await waitFor(100); // Simulate processing time\n        \n        currentConcurrentCalls--;\n        return { naturalWidth: 1920, naturalHeight: 1080 };\n      });\n\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 3,\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      expect(maxConcurrentCalls).toBeLessThanOrEqual(3);\n      expect(result.current.results!.successful).toBe(10);\n    });\n\n    it('should handle different concurrency levels efficiently', async () => {\n      const files = createTestFilesBatch(20);\n      const concurrencyLevels = [1, 2, 4, 8];\n      const results: { [key: number]: number } = {};\n\n      for (const concurrency of concurrencyLevels) {\n        const { result } = renderHook(() => useBatchProcessor({ concurrency }));\n        \n        performanceMonitor.start();\n        \n        await act(async () => {\n          await result.current.startProcessing(\n            files,\n            mockOverlaySettings,\n            mockFrameSettings\n          );\n        });\n        \n        results[concurrency] = performanceMonitor.end(`concurrency-${concurrency}`);\n        \n        expect(result.current.results!.successful).toBe(20);\n      }\n\n      // Higher concurrency should generally be faster (though not always due to overhead)\n      console.log('Concurrency performance results:', results);\n    });\n  });\n\n  describe('Pause and Resume', () => {\n    it('should pause and resume processing', async () => {\n      const files = createTestFilesBatch(10);\n      let processedCount = 0;\n      \n      const { imageProcessingService } = await import('../../services/image-processing.service');\n      (imageProcessingService.loadImage as any).mockImplementation(async () => {\n        processedCount++;\n        await waitFor(200); // Simulate processing time\n        return { naturalWidth: 1920, naturalHeight: 1080 };\n      });\n\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 1,\n      }));\n\n      // Start processing\n      act(() => {\n        result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      // Wait a bit then pause\n      await waitFor(500);\n      \n      act(() => {\n        result.current.pauseProcessing();\n      });\n\n      expect(result.current.isPaused).toBe(true);\n      expect(result.current.progress.status).toBe('paused');\n      \n      const pausedCount = processedCount;\n      \n      // Wait to ensure processing is actually paused\n      await waitFor(500);\n      expect(processedCount).toBe(pausedCount); // Should not have processed more\n\n      // Resume processing\n      act(() => {\n        result.current.resumeProcessing();\n      });\n\n      expect(result.current.isPaused).toBe(false);\n      expect(result.current.progress.status).toBe('processing');\n\n      // Wait for completion\n      await waitFor(3000);\n      \n      expect(result.current.progress.status).toBe('completed');\n      expect(result.current.results!.successful).toBe(10);\n    });\n  });\n\n  describe('Cancellation', () => {\n    it('should cancel processing when requested', async () => {\n      const files = createTestFilesBatch(20);\n      let processedCount = 0;\n      \n      const { imageProcessingService } = await import('../../services/image-processing.service');\n      (imageProcessingService.loadImage as any).mockImplementation(async () => {\n        processedCount++;\n        await waitFor(200);\n        return { naturalWidth: 1920, naturalHeight: 1080 };\n      });\n\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 2,\n      }));\n\n      // Start processing\n      act(() => {\n        result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      // Wait a bit then cancel\n      await waitFor(500);\n      \n      act(() => {\n        result.current.cancelProcessing();\n      });\n\n      expect(result.current.isProcessing).toBe(false);\n      expect(result.current.progress.status).toBe('cancelled');\n      \n      // Processing should have stopped\n      const cancelledCount = processedCount;\n      await waitFor(500);\n      expect(processedCount).toBe(cancelledCount);\n    });\n  });\n\n  describe('Memory Management', () => {\n    it('should manage memory efficiently during large batch processing', async () => {\n      const files = createTestFilesBatch(100);\n      const initialMemory = getMemoryUsage();\n      \n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 4,\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      const finalMemory = getMemoryUsage();\n      \n      expect(result.current.results!.successful).toBe(100);\n      \n      // Memory usage should not increase dramatically\n      if (initialMemory.total > 0) {\n        const memoryIncrease = finalMemory.used - initialMemory.used;\n        const increasePercentage = (memoryIncrease / initialMemory.total) * 100;\n        expect(increasePercentage).toBeLessThan(100); // Should not double memory usage\n      }\n    });\n  });\n\n  describe('Performance Benchmarks', () => {\n    it('should meet performance benchmarks for different batch sizes', async () => {\n      const batchSizes = [5, 10, 25, 50];\n      const benchmarks: { [key: number]: number } = {};\n\n      for (const size of batchSizes) {\n        const files = createTestFilesBatch(size);\n        const { result } = renderHook(() => useBatchProcessor({\n          concurrency: Math.min(4, size),\n        }));\n\n        performanceMonitor.start();\n        \n        await act(async () => {\n          await result.current.startProcessing(\n            files,\n            mockOverlaySettings,\n            mockFrameSettings\n          );\n        });\n        \n        const duration = performanceMonitor.end(`batch-${size}`);\n        benchmarks[size] = duration;\n        \n        expect(result.current.results!.successful).toBe(size);\n        \n        // Performance expectations (adjust based on actual requirements)\n        const expectedMaxTime = size * 200; // 200ms per file maximum\n        expect(duration).toBeLessThan(expectedMaxTime);\n      }\n\n      console.log('Batch processing benchmarks:', benchmarks);\n      \n      // Verify that processing time scales reasonably with batch size\n      const timePerFile5 = benchmarks[5] / 5;\n      const timePerFile50 = benchmarks[50] / 50;\n      \n      // Time per file should not increase dramatically with batch size\n      expect(timePerFile50).toBeLessThan(timePerFile5 * 2);\n    });\n\n    it('should provide detailed performance statistics', async () => {\n      const files = createTestFilesBatch(20);\n      const { result } = renderHook(() => useBatchProcessor({\n        concurrency: 3,\n      }));\n\n      await act(async () => {\n        await result.current.startProcessing(\n          files,\n          mockOverlaySettings,\n          mockFrameSettings\n        );\n      });\n\n      const results = result.current.results!;\n      \n      expect(results.duration).toBeGreaterThan(0);\n      expect(results.averageProcessingTime).toBeGreaterThan(0);\n      expect(results.total).toBe(20);\n      expect(results.successful).toBe(20);\n      expect(results.failed).toBe(0);\n      \n      console.log('Batch processing statistics:', {\n        totalDuration: results.duration,\n        averageProcessingTime: results.averageProcessingTime,\n        throughput: results.total / (results.duration / 1000), // files per second\n      });\n    });\n  });\n});\n"